{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "One we've seen the pipeline function we can take a look behind and find how we can transform and adapt the models to our use cases.\n",
        "\n",
        "In order to do this we will take a look at the tokenizer and the model class![Select_model_HF.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "7uHzFKXAxpS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline"
      ],
      "metadata": {
        "id": "b1Lk7Yawx-Wl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will give us a very generic classes but for some use cases is better to look at the doucmentation as tokenizers may differ from one another.\n",
        "\n",
        "Let's see how this classes work:\n",
        "\n"
      ],
      "metadata": {
        "id": "eFATKddgynmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "B3dAE7cey3_U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a specific model we can use this model to perform the task at hand. Let's keep in mind that not all models can perform all tasks and that some of them are trained for a specific task. As we've loaded one that is generic we can still use it for any task"
      ],
      "metadata": {
        "id": "7HRh9y9OzUjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\",model=model_name,tokenizer=tokenizer)\n",
        "res = classifier(\"I love AI\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfocstVXzmQp",
        "outputId": "e308c2e9-b3e3-45f4-badd-043de97791c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9998302459716797}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, as we can see unde the hood of pipeline what we have is a model and a tokenizer for that model. Let's take a look at the tokenizer to see what is it doing"
      ],
      "metadata": {
        "id": "i8RWaLnT0E-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = \"The monkey climbs the tree using chat-gpt for moving the branches\"\n",
        "res = tokenizer(sequence)\n",
        "print(res)\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "print(tokens)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)\n",
        "decoded_strings = tokenizer.decode(ids)\n",
        "print(decoded_strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YbVY6-m0PDx",
        "outputId": "a6fc22d1-e4dd-4fb2-c39e-597e0b78b4a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 1996, 10608, 18881, 1996, 3392, 2478, 11834, 1011, 14246, 2102, 2005, 3048, 1996, 5628, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "['the', 'monkey', 'climbs', 'the', 'tree', 'using', 'chat', '-', 'gp', '##t', 'for', 'moving', 'the', 'branches']\n",
            "[1996, 10608, 18881, 1996, 3392, 2478, 11834, 1011, 14246, 2102, 2005, 3048, 1996, 5628]\n",
            "the monkey climbs the tree using chat - gpt for moving the branches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we apply the tokenizer directly we get this dictionary:\n",
        "\n",
        "{'input_ids': [101, 1996, 10608, 18881, 1996, 3392, 2478, 11834, 1011, 14246, 2102, 2005, 3048, 1996, 5628, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
        "\n",
        "In here the attention mask key indicates wether the mechanism of attention should use or ignore the token.\n",
        "\n",
        "Then we can see that .tokenize returns the tokens and convert_tokens_to_ids returns the id of the token and .decode returns from the ids the original string.\n",
        "\n",
        "Also taking a look at the ids we can take a look at the start and end of input_ids and we compare it with the convert_to_token_ids we have an extra 101 and 102 which means for the transformers a token as beggining of sentence and end of sentence.\n",
        "\n",
        "[1996, 10608, 18881, 1996, 3392, 2478, 11834, 1011, 14246, 2102, 2005, 3048, 1996, 5628]"
      ],
      "metadata": {
        "id": "GIVgt_iE0rUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, Now let's see how we can combine the code with pytorch or tensorflow"
      ],
      "metadata": {
        "id": "9iVMibCk2ARx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3sX26im2Ezx",
        "outputId": "fa6731d3-ab47-41d0-8877-cdf79f9da85b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "g5i2WZU62I3c"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [\"I've been waiting for a HuggingFace course my whoel life.\",\n",
        "           \"Python is great!\"]\n",
        "\n",
        "res = classifier(X_train)\n",
        "print(res)\n",
        "\n",
        "#In pytorch\n",
        "\n",
        "batch = tokenizer(X_train,padding=True,truncation=True,max_length=512,return_tensors=\"pt\")\n",
        "print(batch)\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model(**batch)\n",
        "  print(f\"OUTPUTS: {outputs}\")\n",
        "  predictions = F.softmax(outputs.logits, dim=1)\n",
        "  print(f\"PREDICTIONS: {predictions}\")\n",
        "  labels = torch.argmax(predictions,dim=1)\n",
        "  print(f\"LABELS: {labels}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koq-JmYC2OcW",
        "outputId": "e73a7637-cf59-445a-b1de-82d4cfa2b503"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'NEGATIVE', 'score': 0.5572958588600159}, {'label': 'POSITIVE', 'score': 0.9998615980148315}]\n",
            "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2040,  2884,  2166,  1012,   102],\n",
            "        [  101, 18750,  2003,  2307,   999,   102,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "OUTPURS: SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2255, -0.0047],\n",
            "        [-4.2745,  4.6111]]), hidden_states=None, attentions=None)\n",
            "PREDICTIONS: tensor([[5.5730e-01, 4.4270e-01],\n",
            "        [1.3835e-04, 9.9986e-01]])\n",
            "LABELS: tensor([0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Althought the output is a little bit messier than before we can see that we have the same.\n",
        "\n",
        "in the outputs we have a dictionary in which we have tensors as we've specified that we wanted tensors in the return_tensors argument to work directly with pytorch, otherwise this would be a list.\n",
        "\n",
        "Then in the Predictions we have again a tensor in which we can see we have the same values for the inference\n",
        "\n",
        "0.557295 vs. 5.5730e-01\n",
        "0.99986159 vs. 9.9986e-01\n",
        "\n",
        "Al igual que en labels las cuales vienen en binario al ser un problema de clasificación binaria:\n",
        "\n",
        "tensor([0, 1]) vs. Negative and Positive"
      ],
      "metadata": {
        "id": "BO5ZHqwD4AYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at how we would save or load a model"
      ],
      "metadata": {
        "id": "R3QIqI505PL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save\n",
        "save_directory = \"saved\"\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "#Load\n",
        "tok = AutoTokenizer.from_pretrained(save_directory)\n",
        "mod = AutoModelForSequenceClassification.from_pretrained(save_directory)"
      ],
      "metadata": {
        "id": "AO02KtlB5LqC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use the model Hub you can filter using the different options and normally there will be examples of code or different ways that you can use that model and download it. If not you can always try to use the generic way to do it and copy the name from the HUb and paste it in the model_name\n",
        "\n"
      ],
      "metadata": {
        "id": "8_pmRrtq6K0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver cómo fine-tunear un modelo con un dataset de manera introductoria"
      ],
      "metadata": {
        "id": "IUd2fE9f7NjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 preparar el dataset\n",
        "#2 load pretrained TOkenizer, call it with dataset -> encoding\n",
        "#3. Build Pytorch Dataset with encodings\n",
        "#4. Load Pretrained model\n",
        "#5. a) Load trainer and train\n",
        "#   b) native Pytorch training loop\n",
        "\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\"test-trainer\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "yA-lA_MU68Jx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}