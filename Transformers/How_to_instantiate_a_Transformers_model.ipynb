{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45HXB8rvJnts",
        "outputId": "84820b65-b429-4234-8f13-c158a1eabd7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "/bin/bash: line 1: Pip: command not found\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!Pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "bert_model = AutoModel.from_pretrained(\"bert-base-cased\")\n",
        "print(type(bert_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyFpO6HEJxF3",
        "outputId": "4f479308-44ad-45fd-fd23-e7e7c55e67af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.bert.modeling_bert.BertModel'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_model = AutoModel.from_pretrained(\"gpt2\")\n",
        "print(type(gpt_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCFAFVW_J9dA",
        "outputId": "92244ca2-e644-49d9-a63a-4f26fd1ba853"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bart_model = AutoModel.from_pretrained(\"facebook/bart-base\")\n",
        "print(type(bart_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3_ZEi2LKEVl",
        "outputId": "ef80d7c0-d7a2-4b73-de61-6e878f2e3e49"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.bart.modeling_bart.BartModel'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Is important to remember that this is actually an API and, as we can see, it's able to instantiate any class of endpoint directly from its checkpoint"
      ],
      "metadata": {
        "id": "y888L91AKNYG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In order to load the ocnfiguration of a model directly without the weights of the model\n",
        "\n",
        "from transformers import AutoConfig\n",
        "\n",
        "bert_model = AutoConfig.from_pretrained(\"bert-base-cased\")\n",
        "print(type(bert_model))\n",
        "gpt_model = AutoConfig.from_pretrained(\"gpt2\")\n",
        "print(type(gpt_model))\n",
        "bart_model = AutoConfig.from_pretrained(\"facebook/bart-base\")\n",
        "print(type(bart_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGV4YC4GKnhu",
        "outputId": "0befea1e-3d26-47e3-dbcc-efa544aa5260"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n",
            "<class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'>\n",
            "<class 'transformers.models.bart.configuration_bart.BartConfig'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#THe configuration of the model contains all the information necessary to create the model architecture\n",
        "\n",
        "from transformers import BertConfig\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
        "print(bert_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXwQR0CaNJ5Z",
        "outputId": "a5225d0f-4a80-4bb3-91f8-c74dbc2724d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.42.4\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#So in this case we would have a model with the same architecture as Bert but whose weights are randomly initialized and we can then train it from scratch with pytorch or tensorflow"
      ],
      "metadata": {
        "id": "q_RFs7OENcMT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The instantiation of the model allows us to change any part of the ocnfiguration using the model features as parameters, for example adjusting the number of layers in the model\n",
        "\n",
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(\"bert-base-cased\",num_hidden_layers = 10)\n",
        "bert_model = BertModel(bert_config)"
      ],
      "metadata": {
        "id": "Q85CCwzjN6-m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Once you've finetuned your model you might want to save it in order to do that we use save_pretrained\n",
        "\n",
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(\"bert-base-cased\",num_hidden_layers = 10)\n",
        "bert_model = BertModel(bert_config)\n",
        "\n",
        "#In here you will train your model\n",
        "\n",
        "#and then save it indicating a path in this case \"my-bert-model\"\n",
        "bert_model.save_pretrained(\"my-bert-model\")\n"
      ],
      "metadata": {
        "id": "uY_pjr9aOjyG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Once you've saved your model you can reload it to use it\n",
        "\n",
        "bert_model = BertModel.from_pretrained(\"my-bert-model\")"
      ],
      "metadata": {
        "id": "Me7QIA-zO2Kg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Before running into the next lesson let's try to see what inputs a model accepts.\n",
        "\n",
        "sequences = [\"Hello!\",\"Cool.\",\"Nice!\"]\n",
        "\n",
        "#Then imagine the tokenizer converts this into encoded sequences. Check that Tensors only accept rectangualr shapes\n",
        "\n",
        "encoded_sequences = [\n",
        "    [101, 7592, 999, 102],\n",
        "    [101, 4658, 1012, 102],\n",
        "    [101, 3835, 999, 102],\n",
        "]\n",
        "\n",
        "#Now that we have our encoded_sequences let's create a tensor\n",
        "\n",
        "import torch\n",
        "\n",
        "model_inputs = torch.tensor(encoded_sequences)\n",
        "\n",
        "#This tensro is the input that we can pass to the model\n",
        "\n",
        "output = bert_model(model_inputs)\n",
        "print(output)\n",
        "\n",
        "#So now we can see that althought the model accepts a wide variety of parameters the only one that is actually necessary is the input IDs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99VheOUYRfxQ",
        "outputId": "84945cef-c76a-43e5-d68d-c116c0a57685"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 2.2655e+00, -6.3633e-01, -1.6527e+00,  ..., -1.8732e+00,\n",
            "           1.2561e+00, -3.4517e-01],\n",
            "         [ 1.3221e+00, -6.5699e-01, -3.3565e-01,  ..., -1.4465e+00,\n",
            "           6.6051e-01,  2.3542e-01],\n",
            "         [ 5.7351e-01, -1.0637e+00,  3.6673e-04,  ..., -1.6006e+00,\n",
            "           1.2246e+00,  2.4427e-01],\n",
            "         [ 1.3976e+00, -3.2150e-01, -1.1603e+00,  ..., -1.8678e+00,\n",
            "           1.0135e+00,  7.5443e-02]],\n",
            "\n",
            "        [[ 1.9290e+00, -3.9329e-01, -1.6955e+00,  ..., -1.5735e+00,\n",
            "           8.8859e-01, -9.3944e-02],\n",
            "         [ 8.1167e-01, -1.0898e+00, -6.4051e-01,  ..., -1.3527e+00,\n",
            "           1.5384e+00,  5.8495e-01],\n",
            "         [ 3.9946e-01, -6.6653e-01, -4.5671e-01,  ..., -1.4571e+00,\n",
            "           1.1462e+00,  8.5234e-01],\n",
            "         [ 1.1294e+00, -1.4786e-01, -1.1229e+00,  ..., -1.5397e+00,\n",
            "           5.7098e-01,  1.1215e-01]],\n",
            "\n",
            "        [[ 2.0569e+00, -6.5363e-01, -1.6974e+00,  ..., -1.4451e+00,\n",
            "           1.0652e+00, -2.8620e-01],\n",
            "         [ 1.7747e+00, -1.2527e+00, -4.9301e-01,  ..., -1.4135e+00,\n",
            "           9.7406e-01, -1.4307e-01],\n",
            "         [ 2.6243e-01, -1.1090e+00, -1.1229e-01,  ..., -1.2680e+00,\n",
            "           9.8951e-01,  2.7133e-01],\n",
            "         [ 1.0899e+00, -3.4199e-01, -1.1870e+00,  ..., -1.6178e+00,\n",
            "           7.5209e-01, -3.7999e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.3587, -0.1583, -0.5461,  ...,  0.0880, -0.0895, -0.2867],\n",
            "        [-0.3623, -0.3710, -0.4294,  ..., -0.0064, -0.1802, -0.3676],\n",
            "        [-0.3314, -0.1747, -0.4466,  ..., -0.1127, -0.2614, -0.3210]],\n",
            "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ]
    }
  ]
}